# Feature Specification: RAGチャットボット

**Feature Branch**: `001-rag-chat`  
**Created**: 2026年2月14日  
**Status**: Draft  
**Input**: User description: "RAGチャットボット（rag-chat）: ユーザーが日本語ドキュメント群をもとに質問できるチャットを実装する。ワークフロー: (1) ドキュメント取り込みと前処理、(2) 埋め込み生成（使用モデルと次元数を明記）、(3) ChromaDB へ格納、(4) 質問時に上位 N 件を検索して生成モデルに渡し応答を生成する。必須機能: ベクトル化スクリプト、検索 API、生成パイプライン、実験ログ（入力・取得ドキュメントID・モデル名・パラメータを含む）、Non‑RAG 比較モード。評価指標: 正答率、ファクト一致率、ユーザビリティ評価（サンプル10問）。再現性: `experiments/` に再現手順とメタデータを保存。制約: シークレットは環境変数で管理、主要ドキュメントは日本語で記載、MVP優先でスケーリングは除外。"

## Clarifications

### Session 2026-02-15

- Q: 埋め込みモデルの選択 → A: GitHub Models の埋め込みモデル（text-embedding-3-small など）を GitHub トークンで使用
- Q: 生成モデルの選択 → A: GitHub Models の言語モデル（GPT-4o、o1、Claude 3.7 Sonnet など）を GitHub トークンで使用
- Q: API インターフェースの形式 → A: REST API（FastAPI などで HTTP エンドポイントを提供）
- Q: GitHub トークンの管理方法 → A: 環境変数（GITHUB_TOKEN）からトークンを読み込み、起動時に検証
- Q: 評価指標（正答率・ファクト一致率）の判定方法 → A: 人間による手動評価（評価者が各回答を1つずつ判定）

## User Scenarios & Testing *(mandatory)*

### User Story 1 - 日本語ドキュメントに基づく質問応答 (Priority: P1)

ユーザーが日本語で質問を入力すると、システムは登録されたドキュメント群から関連情報を検索し、それを基に正確な回答を生成して返します。これにより、ユーザーは大量のドキュメントを手動で検索することなく、必要な情報を素早く取得できます。

**Why this priority**: これは本機能の中核価値であり、RAGチャットボットの基本機能です。この機能単体でユーザーに価値を提供でき、他の全ての機能の基盤となります。

**Independent Test**: 日本語ドキュメントを登録し、それに関連する質問を入力することで、ドキュメント内容に基づいた回答が返ってくることを確認できます。この機能だけで最小限のMVPとして動作します。

**Acceptance Scenarios**:

1. **Given** システムに日本語ドキュメントが登録されている、**When** ユーザーがドキュメント内容に関連する質問を入力する、**Then** システムは関連ドキュメントを検索し、その内容を基にした回答を生成する
2. **Given** ユーザーが質問を入力した、**When** システムが回答を生成する、**Then** 回答には参照したドキュメントの情報（ドキュメントID）が含まれる
3. **Given** システムに登録されていない内容について質問された、**When** 関連ドキュメントが見つからない、**Then** システムは「関連情報が見つかりませんでした」と明示的に伝える

---

### User Story 2 - ドキュメントの登録と前処理 (Priority: P2)

管理者またはシステム担当者が日本語ドキュメント群をシステムに登録すると、システムは自動的にドキュメントを適切な形式に前処理し、ベクトルデータベースに格納します。これにより、ドキュメントが質問応答に利用可能な状態になります。

**Why this priority**: P1の質問応答機能を実現するために必要な準備機能です。この機能がないと検索対象ドキュメントが存在しないため、P1の次に重要です。ただし、初期MVPでは手動でドキュメントを準備することも可能なため、P2としています。

**Independent Test**: ドキュメントファイルを指定してベクトル化スクリプトを実行し、ベクトルデータベースにデータが正しく格納されたことを確認できます。この機能単体で「ドキュメント準備システム」として独立して価値があります。

**Acceptance Scenarios**:

1. **Given** 日本語ドキュメントファイル（複数）が用意されている、**When** ベクトル化スクリプトを実行する、**Then** 各ドキュメントが適切なチャンクに分割され、埋め込みベクトルが生成される
2. **Given** 埋め込みベクトルが生成された、**When** ベクトル化処理が完了する、**Then** すべてのベクトルがベクトルデータベースに格納される
3. **Given** ドキュメント登録処理中にエラーが発生した、**When** エラーが検出される、**Then** どのドキュメントで失敗したかを明確に報告し、他のドキュメントの処理は継続する

---

### User Story 3 - 実験記録と評価 (Priority: P3)

研究者またはシステム評価者が質問を実行すると、システムは質問内容、取得したドキュメントID、使用したモデル、パラメータなどの詳細情報を自動的に記録します。また、用意された評価用質問セット（10問）を使用して、正答率やファクト一致率などの評価指標を測定できます。

**Why this priority**: システムの品質を測定し改善するために重要な機能ですが、基本的な質問応答機能（P1）が動作していれば、初期段階では手動での評価も可能です。継続的な改善のためには必要ですが、MVP段階では優先度を下げられます。

**Independent Test**: 質問を実行し、実験ログファイルに必要な情報（質問、取得ドキュメントID、モデル名、パラメータ）が正しく記録されていることを確認できます。評価スクリプトを実行して評価指標が計算されることを確認できます。

**Acceptance Scenarios**:

1. **Given** ユーザーが質問を実行した、**When** システムが回答を生成する、**Then** 質問内容、取得したドキュメントID、使用モデル名、パラメータがexperiments/配下のログファイルに記録される
2. **Given** 評価用質問セット（10問）が用意されている、**When** 評価スクリプトを実行する、**Then** 各質問の正答率とファクト一致率が計算され、結果が記録される
3. **Given** 実験ログが蓄積されている、**When** ユーザーが過去の実験を確認する、**Then** 再現手順とメタデータを含む実験記録にアクセスできる

---

### User Story 4 - RAG vs Non-RAG 比較評価 (Priority: P4)

評価者がNon-RAGモード（ドキュメント検索を行わず、生成モデルのみで回答）を有効にすると、同じ質問に対してRAGモードとNon-RAGモードの両方で回答を生成し、比較評価できます。これにより、ドキュメント検索の効果を定量的に測定できます。

**Why this priority**: ベースライン比較のための機能であり、システムの有効性を証明するために重要ですが、基本機能の動作には必須ではありません。研究・評価目的の機能として、実用機能の後に実装します。

**Independent Test**: Non-RAGモードを有効にして質問を実行し、ドキュメント検索なしで回答が生成されることを確認できます。同じ質問をRAGモードとNon-RAGモードで実行し、両者の回答を比較できます。

**Acceptance Scenarios**:

1. **Given** Non-RAGモードが有効化されている、**When** ユーザーが質問を入力する、**Then** システムはドキュメント検索をスキップし、生成モデルのみで回答を生成する
2. **Given** 同じ質問がRAGモードとNon-RAGモードで実行された、**When** 両方の回答が生成される、**Then** 実験ログには両モードの結果が区別して記録される
3. **Given** 評価スクリプトが実行される、**When** RAGとNon-RAGの結果が比較される、**Then** 両モードの正答率とファクト一致率の差が計算され報告される

---

### Edge Cases

- **大量のドキュメントが検索にヒットした場合**: システムは上位5件（デフォルト）のみを使用し、取得件数を制限することでレスポンス時間と品質のバランスを取る
- **検索で関連ドキュメントが全く見つからない場合**: システムは「関連情報が見つかりませんでした」と明示的にユーザーに伝え、生成モデルの知識のみに頼った回答は行わない
- **日本語以外の言語で質問された場合**: システムは「日本語で質問してください」というメッセージを返す
- **非常に長い質問文が入力された場合**: システムは質問文を適切な長さに切り詰めるか、「質問を短くしてください」と要求する
- **ドキュメント登録時にサポートされていないファイル形式が渡された場合**: システムはエラーメッセージを表示し、サポートされている形式（テキスト、PDF、Markdownなど）を明示する
- **ベクトルデータベースが利用不可の場合**: システムは接続エラーを検出し、ユーザーに「一時的に利用できません」と通知する
- **APIキーや認証情報が環境変数に設定されていない場合**: システム起動時に GITHUB_TOKEN 環境変数の存在をチェックし、不足している場合は「GITHUB_TOKEN 環境変数が設定されていません」と明確なエラーメッセージで通知する

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: システムは日本語テキストドキュメントを入力として受け取り、適切なサイズのチャンクに分割できなければならない
- **FR-002**: システムは日本語対応の埋め込みモデルを使用して、各ドキュメントチャンクのベクトル表現を生成できなければならない（使用するモデル名と次元数は計画フェーズで決定し、システムドキュメントに明記する）
- **FR-003**: システムは生成された埋め込みベクトルをベクトルデータベースに永続化できなければならない
- **FR-004**: システムはユーザーからの日本語質問を受け付け、質問の埋め込みベクトルを生成できなければならない
- **FR-005**: システムは質問ベクトルに対して類似度検索を実行し、上位N件（デフォルト5件）の関連ドキュメントを取得できなければならない
- **FR-006**: システムは取得したドキュメントと質問を組み合わせてプロンプトを構築し、生成モデルに渡して回答を生成できなければならない
- **FR-007**: システムは生成された回答とともに、参照したドキュメントのIDをユーザーに提示できなければならない
- **FR-008**: システムは各質問応答セッションについて、以下の情報を実験ログとして記録できなければならない：質問内容、取得したドキュメントID、使用した生成モデル名、使用したパラメータ（温度、最大トークン数など）、生成された回答
- **FR-009**: システムはNon-RAGモード（ドキュメント検索を行わず生成モデルのみで回答）を提供し、RAGモードとの比較を可能にしなければならない
- **FR-010**: システムは実験ログを `experiments/` ディレクトリ配下に構造化された形式で保存し、後から再現可能な形で記録しなければならない
- **FR-011**: システムは評価用の質問セット（最低10問）を受け付け、各質問に対する回答を生成し、正答率とファクト一致率を計算できなければならない
- **FR-012**: システムはAPIキーやデータベース接続情報などのシークレット情報を環境変数から読み込まなければならず、コードやファイルにハードコードしてはならない。特に GITHUB_TOKEN 環境変数から GitHub 認証トークンを読み込み、起動時に存在を検証しなければならない
- **FR-013**: システムのREADMEや主要ドキュメントは日本語で記載されなければならない
- **FR-014**: システムは検索実行時にエラーが発生した場合、ユーザーに分かりやすいエラーメッセージを日本語で返さなければならない
- **FR-015**: システムはドキュメント登録処理のスクリプトまたはAPIを提供しなければならない
- **FR-016**: システムは REST API を通じて、ドキュメント登録、質問応答、実験ログ取得などの機能を提供しなければならない

### Key Entities

- **ドキュメント**: システムに登録される日本語の情報源。元のテキスト内容、ファイル名、登録日時などの属性を持つ。ベクトル化のために複数のチャンクに分割される
- **ドキュメントチャンク**: ドキュメントを分割した個別の単位。元のドキュメントへの参照、チャンク内のテキスト、埋め込みベクトル、チャンクIDを持つ。ベクトル検索の基本単位となる
- **質問**: ユーザーが入力する日本語のクエリ。質問テキスト、入力日時、ユーザー識別子（もしあれば）を持つ
- **回答**: システムが生成する応答。回答テキスト、参照したドキュメントチャンクのIDリスト、使用した生成モデル、生成日時を持つ
- **実験記録**: 一つの質問応答セッションの詳細情報。質問、回答、取得したドキュメントIDリスト、モデル名、パラメータ、実行モード（RAG/Non-RAG）、タイムスタンプを含む。`experiments/` ディレクトリに保存される
- **評価結果**: 評価質問セットに対する実行結果。各質問の正答判定、ファクト一致判定、全体の正答率、全体のファクト一致率を含む

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: ユーザーが日本語で質問を入力してから回答が表示されるまでの時間が10秒以内である
- **SC-002**: 評価用質問セット（10問）に対して、システムの正答率が70%以上である
- **SC-003**: 評価用質問セット（10問）に対して、システムのファクト一致率（回答内容がドキュメントの事実と一致する割合）が80%以上である
- **SC-004**: RAGモードの正答率またはファクト一致率が、Non-RAGモードと比較して統計的に有意に高い（10問の評価で差が確認できる）
- **SC-005**: すべての質問応答セッションについて、実験ログが適切に記録され、後から同じ条件で再現実行できる
- **SC-006**: ユーザビリティ評価（10問のサンプル質問を使用）において、回答の有用性が平均3.5点以上（5点満点）と評価される
- **SC-007**: システムが参照した関連ドキュメントIDが各回答に含まれており、ユーザーが情報源を確認できる

## Assumptions

- 埋め込み生成には GitHub Models の埋め込みモデル（text-embedding-3-small など）を GitHub トークンで使用します。OpenAI API キーは不要です
- ベクトルデータベースとしてChromaDBを使用します
- 生成モデルには GitHub Models の言語モデル（GPT-4o、o1、Claude 3.7 Sonnet など）を GitHub トークンで使用します。OpenAI API キーは不要です
- 検索時に取得する関連ドキュメントのデフォルト件数は5件とします
- 評価用質問セットはシステム構築者が用意し、ドメイン知識を必要とする質問を含めます
- 正答率とファクト一致率の評価は、人間の評価者による手動判定を使用します。評価者は各質問の回答を個別に検証し、正答性とファクト一致性を判定します
- MVP段階ではスケーラビリティ（大規模な同時アクセスや膨大なドキュメント数への対応）は対象外とします
- システムは研究・実験目的のため、商用レベルの可用性やセキュリティは初期段階では要求しません

## Scope

### In Scope (この機能に含まれるもの)

- 日本語ドキュメントの取り込みと前処理
- 埋め込みベクトルの生成とベクトルデータベースへの格納
- 質問に対するベクトル検索と関連ドキュメントの取得
- 取得したドキュメントを用いた回答生成
- 実験ログの記録と保存
- RAGモードとNon-RAGモードの両方の実装
- 評価指標（正答率、ファクト一致率）の計算機能
- 評価用質問セット（10問）の実行と結果記録

### Out of Scope (この機能に含まれないもの)

- 多言語対応（日本語以外の言語）
- リアルタイムでのドキュメント更新や自動同期
- 大規模な同時アクセスへの対応（スケーラビリティ）
- ユーザー認証や権限管理
- チャット履歴の永続化や会話の継続機能
- グラフィカルな Web UI またはモバイルアプリ（初期段階では REST API のみで十分。将来的に追加可能）
- 自動的なドキュメント収集やクローリング
- ファインチューニングやモデルの再学習
